name: NBA Data Scrapers

on:
  schedule:
    # Daily stats: 4x per day (8 AM, 12 PM, 6 PM, 11 PM EST = 1 PM, 5 PM, 11 PM, 4 AM UTC)
    - cron: '0 13 * * *'  # 8 AM EST
    - cron: '0 17 * * *'  # 12 PM EST
    - cron: '0 23 * * *'  # 6 PM EST
    - cron: '0 4 * * *'   # 11 PM EST
  workflow_dispatch: # Allow manual trigger

jobs:
  scrape-all:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          cd scraper
          pip install -r requirements.txt
          
      - name: Run daily stats scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          cd scraper
          python daily_stats_scraper.py
        continue-on-error: true
        
      - name: Run value index calculator
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          cd scraper
          python enhanced_value_index.py
        continue-on-error: true

      - name: Run sentiment scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
        run: |
          cd scraper
          python enhanced_sentiment_scraper.py
        continue-on-error: true
        
      - name: Check for failures
        if: failure()
        run: |
          echo "⚠️ One or more scrapers failed. Check the logs above."
          exit 1
